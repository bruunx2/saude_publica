{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bee6d61-5ed3-4588-92e8-979d52594fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15fffbc-cf1d-4d34-95f2-316d212dcd3f",
   "metadata": {},
   "source": [
    "# pre processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa0731d-66e6-4185-92d1-716549194868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv( r\"D:\\OneDrive\\Área de Trabalho\\saude\\saude.csv\", sep=\";\" , encoding=\"latin-1\",low_memory=False, dtype=\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89d9ef3-2f86-4f04-8486-8b5d722113cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "coluna_numerica = [  'Qtde Prescrita Farmácia Curitibana',\n",
    "                     'Qtde Dispensada Farmácia Curitibana',\n",
    "                     'Qtde de Medicamento Não Padronizado',\n",
    "                     'Cômodos',\n",
    "                     'cod_usuario',\n",
    "                     'origem_usuario',\n",
    "                     'residente',\n",
    "                     'cod_profissional' ]\n",
    "\n",
    "for col in coluna_numerica:\n",
    "    df[col] = pd.to_numeric(  df[col].str.replace(',', '.')  )\n",
    "\n",
    "for col in df.columns.tolist():\n",
    "    if df[ col ].dtype == \"string\":\n",
    "        df[col] = df[col].fillna(\"-\")\n",
    "\n",
    "\n",
    "df.loc[ df['Data do Internamento'] == '-', 'Data do Internamento']  = \"01/01/2000 00:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263275c1-179c-4e43-8fdd-97015682d3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d68749-f65b-40dd-8508-aea170e09ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_a_deconsiderar =  [  'Tipo de Unidade',\n",
    "                             'Código da Unidade',\n",
    "                             'Código do Procedimento',\n",
    "                             'Código do CBO',\n",
    "                             'Código do CID',\n",
    "                             'Código do Tipo de Unidade'\n",
    "                           ]       \n",
    "\n",
    "df = df.drop( columns = colunas_a_deconsiderar )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d62d6-f1e2-4cbe-b562-07b2676db31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_enconder = [ 'Sexo',\n",
    "                     'Descrição da Unidade',\n",
    "                     'Descrição do Procedimento',\n",
    "                     'Descrição do CBO',\n",
    "                     'Descrição do CID',\n",
    "                     'Solicitação de Exames',\n",
    "                     'Encaminhamento para Atendimento Especialista',\n",
    "                     'Área de Atuação',\n",
    "                     'Desencadeou Internamento',                    \n",
    "                     'Estabelecimento Solicitante',\n",
    "                     'Estabelecimento Destino',\n",
    "                     'CID do Internamento',\n",
    "                     'Tratamento no Domicílio',\n",
    "                     'Abastecimento',\n",
    "                     'Energia Elétrica',\n",
    "                     'Tipo de Habitação',\n",
    "                     'Destino Lixo',\n",
    "                     'Fezes/Urina',          \n",
    "                     'Em Caso de Doença',\n",
    "                     'Grupo Comunitário',\n",
    "                     'Meio de Comunicacao',\n",
    "                     'Meio de Transporte',\n",
    "                     'Municício',\n",
    "                     'Bairro',\n",
    "                     'Nacionalidade',\n",
    "                     ]\n",
    "\n",
    "column_encoder = {}\n",
    "for column in columns_enconder:\n",
    "    column_encoder[ column ]  = LabelEncoder()\n",
    "    column_encoder[ column ].fit( df[ column].unique().tolist() )\n",
    "    df[ column ] = column_encoder[ column ].transform(df[ column ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92994516-d0cd-42e3-b0a4-cb0fc5caf250",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Data do Atendimento'] = pd.to_datetime( df['Data do Atendimento'], format = \"%d/%m/%Y %H:%M:%S\" )\n",
    "df['Data de Nascimento'] = pd.to_datetime( df['Data de Nascimento'] , format = \"%d/%m/%Y %H:%M:%S\")\n",
    "df['Data do Internamento']  = pd.to_datetime( df['Data do Internamento']  , format = \"%d/%m/%Y %H:%M:%S\", errors=\"coerce\")\n",
    "\n",
    "df['Data do Atendimento'] = df['Data do Atendimento'].astype('int64')// 1e9\n",
    "df['Data de Nascimento'] = df['Data de Nascimento'].astype('int64')// 1e9\n",
    "df['Data do Internamento'] = pd.to_datetime(df['Data do Internamento'])\n",
    "df['Data do Internamento'] = df['Data do Internamento'].astype('int64') // 1e9\n",
    "\n",
    "df.loc[ df['Data do Internamento'] == 946684800.0, 'Data do Internamento' ] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d3ab4-84b7-47c0-bf9e-64dd3494cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_selecionadas = [ 'Data do Atendimento','Descrição da Unidade', 'Data de Nascimento', 'Sexo', 'Meio de Transporte','Municício','Bairro','Descrição do CID']\n",
    "df2= df[colunas_selecionadas]\n",
    "df2.to_parquet(r\"./base.parquet.gzip\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f1101-e22e-411a-ba12-42467e0fc163",
   "metadata": {},
   "source": [
    "# treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d1fd21b-186e-4d81-af19-6fd225a4245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_parquet( r\"./base.parquet.gzip\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78c0110e-7b5b-4bec-93dd-46b092f957df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df2.to_numpy(dtype=np.float32)\n",
    "\n",
    "train_size = int(0.8 * len(data))\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "\n",
    "del data\n",
    "\n",
    "X_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]\n",
    "X_test = test_data[:, :-1]\n",
    "y_test = test_data[:, -1]\n",
    "\n",
    "del train_data \n",
    "del test_data \n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "X_train_tensor = (X_train_tensor - X_train_tensor.mean()) / X_train_tensor.std()\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "\n",
    "del X_train, y_train, X_test, y_test\n",
    "\n",
    "# Expandir os rótulos de destino para corresponder à forma da saída da rede\n",
    "y_train_tensor_expanded = y_train_tensor.unsqueeze(1)\n",
    "y_train_tensor_expanded = (y_train_tensor_expanded - y_train_tensor_expanded.mean()) / y_train_tensor_expanded.std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0087ab-fa2a-4216-9100-c83e34b680b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0d3e3298-6e86-4618-99ed-6e7526246a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc  = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, self.hidden_size)\n",
    "        out, hidden = self.rnn(x, h0)\n",
    "        \n",
    "        return out, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05afc5ef-c9d0-448c-b3fc-0b0c0fe8c2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49801071-1ca1-403a-99cd-e2fbe2eb8ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 15\n",
    "output_size = 1\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "batch_size = 5012 \n",
    "num_samples = X_train_tensor.size(0)\n",
    "\n",
    "\n",
    "print(input_size) \n",
    "model = Net(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "writer = SummaryWriter('runs/rnn_experiment')\n",
    "\n",
    "hidden_prev = torch.zeros( 1, hidden_size )\n",
    "\n",
    "if os.path.exists( r\"model.pth\" ):\n",
    "    print(\"lendo modelo\")\n",
    "    model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "# Treinar o modelo\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        X_batch = X_train_tensor[i:i+batch_size]\n",
    "        y_batch = y_train_tensor_expanded[i:i+batch_size]       \n",
    "\n",
    "        outputs, hidden_prev = model(X_batch)\n",
    "        hidden_prev = hidden_prev.detach()\n",
    "        \n",
    "        loss = criterion(outputs.squeeze(), y_batch)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_item = loss.item()\n",
    "        epoch_loss += loss_item\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += y_batch.size(0)\n",
    "        correct_predictions += (predicted == y_batch).sum().item()\n",
    "        \n",
    "    \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss_item:.4f}', end=\"\\r\")\n",
    "\n",
    "        accuracy = 100 * correct_predictions / total_samples\n",
    "        epoch_loss = epoch_loss / (num_samples / batch_size)\n",
    "        torch.save( model.state_dict(), 'model.pth' )\n",
    "        writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train', accuracy, epoch)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba6659-4ce2-44c3-a034-60f48e8f3a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
